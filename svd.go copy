package main

import (
	"bytes"
	// "compress/gzip"
	"encoding/json"
	// "encoding/binary"
	"encoding/gob"
	"fmt"
	"io/ioutil"
	"log"
	"math"
	"os"
	"os/exec"
	"path/filepath"
	"regexp"
	"sort"
	"strconv"
	"strings"
	// "reflect"

	"github.com/bbalet/stopwords"
	"github.com/gonum/matrix"
	"github.com/gonum/matrix/mat64"
	"github.com/reiver/go-porterstemmer"
	"github.com/fatlotus/gauss"
)

// type phrase struct {
// 	word  string  `json:"word"`
// 	tf    float64 `json:"tf"`
// 	df    int     `json:"df"`
// 	idf   float64 `json:"idf"`
// 	tfidf float64 `json:"tfidf"`
// 	fl    bool    `json:"fl"`
// }

type clustersData struct {
	Clusters       map[string][]int    `json:"Clusters"`
	ClustersLabels map[string]string   `json:"ClusterLabels"`
	ClustersFiles  map[string][]string `json:"ClusterFiles"`
}

type MatrixE struct {
	Terms 	[][]float64 	`json:"Terms"`
	Docs 	[][]float64  	`json:"Docs"`
}

type phrase struct {
	word   string
	wordID int
	DocID  []int
	count  int
	tf     []int
	df     int
	idf    float64
	tfidf  []float64
	wfl    bool
}

type similarity struct {
	dname     string
	simlarity float64
}
type Bysimilarity []similarity

var dID, wID int
var svd mat64.SVD

func main() {

	searchDir := "./papers/testdocsR&J"

	firstTime := true //Will let the next loop know if this is the first clustering or not

	var docsToInclude []int //Will be the array with indices of documents to include in clustering
	initialThreshold := 0.9

	var initialFileNames []string

	totalCount := 0
	var initialCluster map[string][]int
	var initialClusterArr [][]int
	var initialClusterArrLabels []string

	var finalClusterArr [][]int
	var finalClusterArrLabels []string
	// for(len(docsToInclude) > 5 || firstTime == true) {
	// for firstTime || totalCount < len(initialClusterArr) + 1 {
	for totalCount < 1 {
		totalCount = totalCount + 1
		dID = -1
		wID = -1
		// similarities := []similarity{}
		termdocumentMatrix := []float64{}
		var tosort map[string]int
		var sorted []string
		tosort = make(map[string]int)

		fileNames := []string{}
		var phrases map[string]phrase
		phrases = make(map[string]phrase)

		var docID map[int]string
		docID = make(map[int]string)

		if firstTime == false {
			docsToInclude = initialClusterArr[totalCount-2]
		}

		count := 0
		err := filepath.Walk(searchDir, func(path string, f os.FileInfo, err error) error {
			if strings.Contains(path, ".txt") {
				if firstTime == true {
					docsToInclude = append(docsToInclude, count)
				}
				if checker(docsToInclude, count) {
					fileNames = append(fileNames, path)
				}
				count = count + 1
			}
			return nil
		})
		if err != nil {
			log.Fatal(err)
		}
		numeberofdocs := len(fileNames)

		if firstTime == true {
			initialFileNames = fileNames
		}

		// fmt.Println("number of docs = ", numeberofdocs)
		for _, fileName := range fileNames[:] {
			//------------formating file names-----------
			r := strings.NewReplacer("+", " ",
				".txt", "")
			result := r.Replace(fileName)
			var re = regexp.MustCompile(`testdata2.+\/`)
			fname := re.ReplaceAllString(result, "")
			//------------file name formatting ends------------
			dID = dID + 1
			docID[dID] = fname
			frequency(fileName, phrases)
			for k := range phrases {
				tmp := phrases[k]
				if tmp.count > 0 {
					tmp.df++
					tmp.tf = append(tmp.tf, tmp.count)
					tmp.DocID = append(tmp.DocID, dID)
				}
				tmp.count = 0
				phrases[k] = tmp
			}
		}
		for k := range phrases {
			tmp := phrases[k]
			tmp.idf = math.Log10(float64(numeberofdocs) / float64(1+tmp.df))
			for _, v := range tmp.tf {
				tmp.tfidf = append(tmp.tfidf, tmp.idf*float64(v))
			}
			phrases[k] = tmp
			tosort[k] = tmp.wordID
		}
		sorted = sortmapbyvalue(tosort)
		for _, w := range sorted {
			termFreqs := make([]float64, numeberofdocs)
			tmp := phrases[w]
			for i, v := range tmp.DocID {
				termFreqs[v] = float64(toFixed(tmp.tfidf[i], 4))
			}
			termdocumentMatrix = append(termdocumentMatrix, termFreqs...)
		}

		//--------------------printing tfidf matrix---------------//
		mapOfMaps := make(map[int][]string, numeberofdocs)

		orderedPhrases := make([]string, len(phrases))
		counter := 0
		for k, _ := range phrases {
			orderedPhrases[counter] = k
			counter++
		}

		for i := 0; i < numeberofdocs; i++ {
			var m []string
			mapOfMaps[i] = m
		}
		for _, v := range phrases {
			for i := 0; i < len(v.DocID); i++ {
				var buffer bytes.Buffer
				buffer.WriteString(v.word)
				buffer.WriteString(":")
				buffer.WriteString(strconv.FormatFloat(v.tfidf[i], 'f', -1, 64))
				if v.tfidf[i] > .00000001 || v.tfidf[i] < -.00000001 {
					mapOfMaps[v.DocID[i]] = append(mapOfMaps[v.DocID[i]], buffer.String())
				}
			}

		}
		//---------------------printing done-----------------------//
		// fmt.Println(termdocumentMatrix)
		newtd := make([][]float64, len(phrases))
		for i := 0; i < len(phrases); i++{
			newtd[i] = make([]float64, numeberofdocs)
		}
		count = 0
		for i := 0; i < len(phrases); i++{
			for j := 0; j < numeberofdocs; j++{
				newtd[i][j] = termdocumentMatrix[count]
				count = count + 1
			}
		}
		uNew,sNew,vNew := gauss.SVD(gauss.Matrix(newtd))
		// fmt.Println("uNew", uNew)
		fmt.Println("uNew Data", uNew.Data)
		// fmt.Println("uNew Shape", uNew.Shape)
		fmt.Println("sNew", sNew)
		fmt.Println("vNew DATA", vNew.Data)

		fmt.Println(len(phrases))
		tdm2 := mat64.NewDense(len(phrases), numeberofdocs, termdocumentMatrix)
		fmt.Println(len(phrases))
		r1, c1 := tdm2.Dims()
		fmt.Println("TDM2: ", r1, c1)
		ok := svd.Factorize(tdm2, matrix.SVDFull)
		fmt.Println(len(phrases))
		if !ok {
			fmt.Errorf("SVD failed")
		}
		r := uNew.Shape[0]
		c := uNew.Shape[1]
		// fmt.Println("S:", s)
		// fmt.Println(r,c)
		LRF := 0 // low rank factor 'sometimes refered to as 'k' in different texts'
		slen := len(sNew.Data) - LRF
		//-------------- extracting a low rank matrix ------------//
		TermE := mat64.NewDense(r, slen, nil)
		eigenvalues := mat64.NewDense(slen, slen, nil)
		c = vNew.Shape[1]
		DocE := mat64.NewDense(slen, c, nil)
		for i := 0; i < slen; i++ {
			eigenvalues.Set(i, i, sNew.Data[i])
		}
		vSmall := mat64.NewDense(slen, c, nil)
		r, c = vSmall.Dims()
		//fmt.Println(r, c)
		for i := 0; i < slen; i++ {
			for j := 0; j < c; j++ {
				vSmall.Set(i, j, vNew.Data[(j * slen) + i])
			}
		}
		r = uNew.Shape[0]
		c = uNew.Shape[1]
		uSmall := mat64.NewDense(r, slen, nil)
		count = 0
		for i := 0; i < r; i++ {
			for j := 0; j < slen; j++ {
				uSmall.Set(i, j, uNew.Data[count])
				count = count + 1
			}
		}
		//--------------------low rank extraction done -------------//
		//---------------now scaling the term space and doc space by the eigen values----------------//
		var matrices MatrixE
		TermE.Mul(uSmall, eigenvalues)
		DocE.Mul(eigenvalues, vSmall)
		fmt.Println("TERME", TermE)
		fmt.Println("DOCE", DocE)
		
		Tr, Tc := TermE.Dims()
		Dr, Dc := DocE.Dims()

		matrices.Terms = make([][]float64, Tr)
		for i := range matrices.Terms {
			matrices.Terms[i] = make([]float64, Tc)
		}
		for i := 0; i < Tr; i++ {
			for j := 0; j < Tc; j++ {
				matrices.Terms[i][j] = TermE.At(i, j)
			}
		}
		matrices.Docs = make([][]float64, Dr)
		for i := range matrices.Docs {
			matrices.Docs[i] = make([]float64, Dc)
		}
		for i := 0; i < Dr; i++ {
			for j := 0; j < Dc; j++ {
				matrices.Docs[i][j] = DocE.At(i, j)
			}
		}

		// swag,err := json.MarshalIndent(&matrices, "", "\t")
		// if err != nil {
		// 	fmt.Printf("There was an error encoding the json. err = %s", err)
		// 	return
		// }

		// err = ioutil.WriteFile("TermDocs.txt", swag, 0644)

		//------Encode GOB data--------------
		encBuf := new(bytes.Buffer)
		err = gob.NewEncoder(encBuf).Encode(matrices)
		if err != nil {
			log.Fatal(err)
		}
		value := encBuf.Bytes()
		err = ioutil.WriteFile("TermDocsTemp.txt", value, 0644)

		buf := new(bytes.Buffer)
		var pi float64 = math.Pi
		err = binary.Write(buf, binary.LittleEndian, pi)
		if err != nil {
			fmt.Println("binary.Write failed:", err)
		}

		fmt.Printf("% x\n", value)

		READ TERME & DOCE
		raw, err := ioutil.ReadFile("TermDocs.txt")
		if err != nil {
			fmt.Println(err.Error())
			os.Exit(1)
		}
		var matr MatrixE
		json.Unmarshal(raw, &matr)

		---------Unpack GOB data-----------------
		raw, err := ioutil.ReadFile("TermDocs.txt")
		decBuf := bytes.NewBuffer(raw)
		bookOut := MatrixE{}
		err = gob.NewDecoder(decBuf).Decode(&bookOut)

		fmt.Println("TERMS", bookOut.Terms)
		fmt.Println("DOCS", bookOut.Docs)

		TermRows := len(bookOut.Terms)
		TermCols := len(bookOut.Terms[0])
		DocRows := len(bookOut.Docs)
		DocCols := len(bookOut.Docs[0])
		TermDense := mat64.NewDense(TermRows, TermCols, nil)
		for i := 0; i < TermRows; i++ {
			for j := 0; j < TermCols; j++ {
				TermDense.Set(i, j, bookOut.Terms[i][j])
			}
		}
		DocDense := mat64.NewDense(DocRows, DocCols, nil)
		for i := 0; i < DocRows; i++ {
			for j := 0; j < DocCols; j++ {
				DocDense.Set(i, j, bookOut.Docs[i][j])
			}
		}

		//--------------------scaling done-----------------------------------------------//
		raw, err = ioutil.ReadFile("Query.txt")
		fmt.Println(string(raw))

		query := string(raw)
		queryfields := strings.Fields(query)
		_, c = TermDense.Dims()
		qa := mat64.NewVector(c, nil) // add all query vectors in qa
		q := mat64.NewVector(c, nil)  // q will hold scaled qa
		for _, v := range queryfields {
			stemmedqueryfield := porterstemmer.StemString(strings.ToLower(v))
			queryfieldvector := TermDense.RowView(phrases[stemmedqueryfield].wordID)
			qa.AddVec(queryfieldvector, qa)
		}
		q.ScaleVec(float64(1)/float64(len(queryfields)), qa)
		//---------------------Measure cosine similarity with all the doc vectors------------//
		_, c = DocDense.Dims()
		for i := 0; i < c; i++ {
			d := DocDense.ColView(i)
			csm := cosinesimilarity(d, q, docID[i])
			similarities = append(similarities, csm)
		}
		sort.Sort(Bysimilarity(similarities))
		//------------printing the result----------------------------//
		count = 0
		for _, v := range similarities {
			if count < 10 {	
				fmt.Println(v.dname, v.simlarity)
			}
			count = count + 1
		}

		//===========================================================
		printMatrix(DocE, mapOfMaps, fileNames)
		//===========================================================
		threshold := initialThreshold
		if firstTime == false {
			threshold = initialThreshold - 0.03
		}

		tempDocsToInclude, tempLabels, _ := runClustering(threshold, slen, fileNames)

		for k, v := range tempDocsToInclude {
			for i := 0; i < len(v); i++ {
				v[i] = docsToInclude[v[i]]
			}
			if firstTime == false {
				finalClusterArr = append(finalClusterArr, v)
				finalClusterArrLabels = append(finalClusterArrLabels, tempLabels[k])
			}
		}
		if firstTime == false && len(docsToInclude) < 2 {
			finalClusterArr = append(finalClusterArr, docsToInclude)
			finalClusterArrLabels = append(finalClusterArrLabels, initialClusterArrLabels[totalCount-2])
		}
		// docsToInclude = tempDocsToInclude
		if firstTime == true {
			initialCluster = tempDocsToInclude
			fmt.Println("Initial Clusters")
			for k, v := range initialCluster {
				fmt.Println("--------------------------------------------------------")
				fmt.Println(k, v)
				for i := 0; i < len(v); i++ {
					fileString := initialFileNames[v[i]]
					fileStringArr := strings.Split(fileString, "/")
					fmt.Println(fileStringArr[len(fileStringArr)-1])
				}
				fmt.Println(tempLabels[k])
				initialClusterArr = append(initialClusterArr, v)
				initialClusterArrLabels = append(initialClusterArrLabels, tempLabels[k])
			}
			firstTime = false
		} else {
			// fmt.Println("Next Clsuters")
			// fmt.Println(tempDocsToInclude)
		}
	}
	for i := 0; i < len(finalClusterArr); i++ {
		fmt.Println("--------------------------------------------------------")
		fmt.Println(finalClusterArr[i])
		for j := 0; j < len(finalClusterArr[i]); j++ {
			fileString := initialFileNames[finalClusterArr[i][j]]
			fileStringArr := strings.Split(fileString, "/")
			fmt.Println(fileStringArr[len(fileStringArr)-1])

			// fmt.Println(initialFileNames[finalClusterArr[i][j]])
		}
		fmt.Println(finalClusterArrLabels[i])
	}
}

func runClustering(threshold float64, dimensions int, fileNames []string) (map[string][]int, map[string]string, map[string][]string) {
	f, _ := os.Create("ClusterScript.sh")
	f.WriteString("#!/bin/sh\n\n")
	f.WriteString("python cluster.py ")
	f.WriteString(strconv.FormatFloat(threshold, 'f', -1, 64))
	f.WriteString(" ")
	f.WriteString(strconv.Itoa(dimensions))

	app := "/Users/varuncherukuri/Documents/College/Summer3/lsa/svd/ClusterScript.sh"
	println("Running Python Script ...")
	cmd := exec.Command(app)
	stdout, err := cmd.CombinedOutput()

	if err != nil {
		println("ERROR", err.Error())
		return nil, nil, nil
	} else {
		println("Ran Python Script")
	}
	println(string(stdout))

	raw, err := ioutil.ReadFile("clusterData.txt")
	if err != nil {
		fmt.Println(err.Error())
		os.Exit(1)
	}
	var c clustersData
	json.Unmarshal(raw, &c)
	// for k,v := range(c.Clusters){
	// 	fmt.Println("CLUSTER", k, ":", v)
	// 	for i := 0; i < len(v); i++{
	// 		fmt.Println(fileNames[v[i]])
	// 	}
	// }
	// fmt.Println("*****************************************")
	// for k,v := range(c.ClustersLabels){
	// 	fmt.Println("CLUSTER", k, ":", v)
	// 	fmt.Println("------------------------------------------")
	// }

	// return c.Clusters[largestKey]
	return c.Clusters, c.ClustersLabels, c.ClustersFiles
}

//Find max term in map
func findMax(m map[string]float64) map[string]float64 {
	var tempMaxKey1 string
	var tempMaxVal1 float64
	var tempMaxKey2 string
	var tempMaxVal2 float64
	var tempMaxKey3 string
	var tempMaxVal3 float64
	var tempMaxKey4 string
	var tempMaxVal4 float64
	var tempMaxKey5 string
	var tempMaxVal5 float64
	for k, v := range m {
		if v > tempMaxVal1 {
			tempMaxVal1 = v
			tempMaxKey1 = k
		} else if v > tempMaxVal2 {
			tempMaxVal2 = v
			tempMaxKey2 = k
		} else if v > tempMaxVal3 {
			tempMaxVal3 = v
			tempMaxKey3 = k
		} else if v > tempMaxVal4 {
			tempMaxVal4 = v
			tempMaxKey4 = k
		} else if v > tempMaxVal5 {
			tempMaxVal5 = v
			tempMaxKey5 = k
		}
	}
	ret := make(map[string]float64, 5)
	ret[tempMaxKey1] = tempMaxVal1
	ret[tempMaxKey2] = tempMaxVal2
	ret[tempMaxKey3] = tempMaxVal3
	ret[tempMaxKey4] = tempMaxVal4
	ret[tempMaxKey5] = tempMaxVal5
	return ret
}

//Prints out matrix in correct format for later python scripts
func printMatrix(matr *mat64.Dense, m map[int][]string, fileNames []string) {
	f, _ := os.Create("outputMatrix.txt")
	a, b := matr.Dims()
	Cols := make([][]float64, b)
	for i := 0; i < b; i++ {
		Cols[i] = make([]float64, a)
		CurrCol := matr.ColView(i)
		for j := 0; j < a; j++ {
			Cols[i][j] = CurrCol.At(j, 0)
			if Cols[i][j] < 0.0000001 && Cols[i][j] > 0 {
				Cols[i][j] = 0.0
			}
			if Cols[i][j] > -0.0000001 && Cols[i][j] < 0 {
				Cols[i][j] = 0.0
			}
		}
	}
	// fmt.Println("Cols:", Cols)
	for i := 0; i < b; i++ {
		for j := 0; j < a; j++ {
			// fmt.Print(Cols[i][j])
			f.WriteString(strconv.FormatFloat(Cols[i][j], 'f', -1, 64))
			if j < a-1 {
				// fmt.Print(",")
				f.WriteString(",")
			}
		}
		// fmt.Print(",")
		f.WriteString(",")
		for j := 0; j < len(m[i]); j++ {
			// fmt.Print(m[i][j],"|")
			f.WriteString(m[i][j])
			f.WriteString("|")
		}
		// fmt.Print(",", fileNames[i])
		// fmt.Print("\n")
		f.WriteString(",")
		f.WriteString(fileNames[i])
		f.WriteString("\n")
	}
}

//Check if element exists in array
func checker(arr []int, element int) bool {
	for i := 0; i < len(arr); i++ {
		if arr[i] == element {
			return true
		}
	}
	return false
}

//------------comment the following if output/directory is not required-------------//

//-------------------------clearing done ---------------------//

func frequency(fileName string, p map[string]phrase) {
	fileContent, err := ioutil.ReadFile(fileName)
	if err != nil {
		return
	}
	fileL := strings.ToLower(string(fileContent))
	cleanContent := stopwords.CleanString(fileL, "en", true)
	s := strings.Fields(cleanContent)
	
	// for _, i := range s {
	// 	stem := porterstemmer.StemString(i)
	// 	tmp := p[stem]
	// 	tmp.word = stem
	// 	tmp.count++
	// 	if tmp.wfl != true {
	// 		wID = wID + 1
	// 		tmp.wordID = wID
	// 		tmp.wfl = true
	// 	}
	// 	p[stem] = tmp
	// }
	for i := 0; i < len(s) - 1; i++{
		stem1 := porterstemmer.StemString(s[i])
		stem2 := porterstemmer.StemString(s[i + 1])
		stemFinal := stem1 + " " + stem2

		tmp := p[stemFinal]
		tmp.word = stemFinal
		tmp.count++
		if tmp.wfl != true {
			wID = wID + 1
			tmp.wordID = wID
			tmp.wfl = true
		}
		p[stemFinal] = tmp
	}
	// for i := 0; i < len(s) - 2; i++{
	// 	stem1 := porterstemmer.StemString(s[i])
	// 	stem2 := porterstemmer.StemString(s[i + 1])
	// 	stem3 := porterstemmer.StemString(s[i + 2])
	// 	stemFinal := stem1 + " " + stem2 + " " + stem3

	// 	tmp := p[stemFinal]
	// 	tmp.word = stemFinal
	// 	tmp.count++
	// 	if tmp.wfl != true {
	// 		wID = wID + 1
	// 		tmp.wordID = wID
	// 		tmp.wfl = true
	// 	}
	// 	p[stemFinal] = tmp
	// }
}

//---------------------write output---------------------//
func writeoutput(sorted []string, phrases map[string]phrase) {
	fmt.Println("word wID dID count tf df idf tfidf wfl")
	for _, v := range sorted {
		fmt.Println(phrases[v])
	}

}

func del(m map[string]phrase) {
	for k := range m {
		delete(m, k)
	}
}
func round(num float64) int {
	return int(num + math.Copysign(0.5, num))
}

func toFixed(num float64, precision int) float64 {
	output := math.Pow(10, float64(precision))
	return float64(round(num*output)) / output
}

//------------------------sorting starts here---------------------//
type sortedMap struct {
	m map[string]int
	s []string
}

func (sm *sortedMap) Len() int {
	return len(sm.m)
}

func (sm *sortedMap) Less(i, j int) bool {
	return sm.m[sm.s[i]] < sm.m[sm.s[j]]
}

func (sm *sortedMap) Swap(i, j int) {
	sm.s[i], sm.s[j] = sm.s[j], sm.s[i]
}

func sortmapbyvalue(m map[string]int) []string {
	sm := new(sortedMap)
	sm.m = m
	sm.s = make([]string, len(m))
	i := 0
	for key := range m {
		sm.s[i] = key
		i++
	}
	sort.Sort(sm)
	return sm.s
}

func (a Bysimilarity) Len() int           { return len(a) }
func (a Bysimilarity) Swap(i, j int)      { a[i], a[j] = a[j], a[i] }
func (a Bysimilarity) Less(i, j int) bool { return a[i].simlarity > a[j].simlarity }

//----------------------------------------------------------------------//

func extractSVD(svd *mat64.SVD) (s []float64, u, v *mat64.Dense) {
	var um, vm mat64.Dense
	um.UFromSVD(svd)
	vm.VFromSVD(svd)
	s = svd.Values(nil)
	return s, &um, &vm
}

func printdense(m *mat64.Dense, name string) {
	r, c := m.Dims()
	fmt.Println("Matrix ", name, r, c)
	for i := 0; i < r; i++ {
		for j := 0; j < c; j++ {
			fmt.Printf("%f	", m.At(i, j))
		}
		fmt.Printf("\n")
	}
}

func cosinesimilarity(a *mat64.Vector, b *mat64.Vector, docname string) similarity {
	var sum float64
	sum = 0
	moda := 0.0
	modb := 0.0
	var tmp similarity
	for i := 0; i < a.Len(); i++ {
		moda += math.Pow(a.At(i, 0), 2)
		modb += math.Pow(b.At(i, 0), 2)
		sum += a.At(i, 0) * b.At(i, 0)
	}
	tmp.dname = docname
	tmp.simlarity = sum / (math.Sqrt(moda) * math.Sqrt(modb))
	// fmt.Println(tmp.simlarity)
	return tmp
}
